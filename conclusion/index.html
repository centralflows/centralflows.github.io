<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Conclusion: why central flows?</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="../styles.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="../js/mathjax-config.js"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../js/video-controls.js"></script>
</head>
<body>
    <nav class="top-nav">
        <div class="top-nav-left">
            <a href="https://arxiv.org/abs/2410.24206">ðŸ“„ Paper</a>
        </div>
        <div class="top-nav-center">
            <a href="../">Introduction</a>
            <span class="separator">|</span>
            <a href="../part1">Part I</a>
            <span class="separator">|</span>
            <a href="../part2">Part II</a>
            <span class="separator">|</span>
            <a href="../part3">Part III</a>
            <span class="separator">|</span>
            <a href="../conclusion" class="active">Conclusion</a>
        </div>
        <div class="top-nav-right">
            <a href="https://github.com/locuslab/central_flows">ðŸ’» Code</a>
        </div>
    </nav>

    <p class="companion-text">
        This is the companion website for the paper <a href="https://arxiv.org/abs/2410.24206">Understanding Optimization in Deep Learning with Central Flows</a>, published at ICLR 2025.
     </p>

    <h1>Conclusion: why central flows?</h1>

    <p class="body-text">
        Optimization is a core component of deep learning.
        <!-- Regardless of whether you're pre-training a large Transformer to predict the next token, "fine-tuning" this Transformer to become an assistant, or training a diffusion model, you are running an iterative optimization algorithm, -->
        If you are doing deep learning, you are running an iterative optimization algorithm,
        and there are certain optimization-related concerns that always come up:
        What does the learning rate do, and how should I set it?  Why is my gradient behaving like that? Why does one optimizer work better than another on a given task?  How can we build a better optimizer?
        A <strong>theory of optimization for deep learning</strong> would provide a <strong>language for reasoning</strong> about these questions.
    </p>
    <p class="body-text">
        Yet, there is currently no consensus on what form this theory should take.
    In classical optimization theory, there are perhaps two prevalent styles of analysis, yet neither seems well-suited for deep learning.
    </p>
    <p class="body-text">
        First, there are local convergence analyses, which describe the optimizer's behavior in the neighborhood of a minimum.
        The problem with these is that deep learning mostly does not happen in the neighborhood of a minimum.
        In many cases, training terminates before anything remotely resembling a minimum is reached.
        Even if there are situations where training does eventually reach a minimum, the practitioner cares equally about the whole training process, and does not care disproportionately about the last moments.
    </p>
    <p class="body-text">
        Second, there are global convergence analyses, which aim to prove convergence to a minimum from any initialization.
        The problem with these is that, for real networks on real problems, nobody knows how to meaningfully characterize the rate of convergence of any optimizer.
        If we can't meaningfully characterize the rate for any single optimizer, then we can't meaningfully compare two optimizers by comparing their respective rates.
        <!-- It's possible that global convergence analyses only make sense in the context of convex optimization. -->
    </p>
    <p class="body-text">
        Another idea is to analyze optimization in "toy" settings, where the model and the dataset are simple enough for analysis to be tractable.
        But while meaningful results can often be proven about the toy model, it is never clear if or how such results would generalize to practical settings.
        For a practitioner training a real neural net on a real dataset, an analysis of a toy setting does not suggest anything concrete about the problem at hand.
    </p>
    <p class="body-text">
        In light of these limitations, we advocate for a theory of optimization that focuses on studying the <em>local dynamics</em> of the optimizer <em>throughout training</em>.
        (Note that we are <a href="https://arxiv.org/abs/2009.11162">by no means</a> the <a href="https://arxiv.org/abs/2205.10287">first</a> to advocate for this idea.)
        In the deterministic setting, what makes these dynamics particularly interesting are the <em>oscillations</em> that arise from the interaction between the discrete update rule and the local loss landscape.
        Without understanding these oscillatory dynamics, it is not possible to understand the behavior of an optimizer, or the function of its hyperparameters.
    <p class="body-text">
        To understand an optimizer's oscillatory dynamics, we derive a central flow that models the time-averaged, or smoothed, trajectory of the optimizer.
        This central flow renders <em>explicit</em> the behaviors that were previously <em>implicit</em> in the optimizer's oscillatory dynamics.
    </p>
    <p class="body-text">
        To be sure, a central flow analysis does not reveal everything we'd like to know about the optimization process.
        For example, our analysis does not allow us to characterize the global rate at which the training loss will decrease.
        For another example, although we show that optimizers implicitly follow a curvature-penalized gradient flow, we do not explain what such a curvature penalty means for learning.
        These are important problems for deep learning theory that are beyond the scope of the current work.
    </p>
    <p class="body-text">
        Yet, we argue that a central flow analysis is a <strong>necessary step</strong> towards understanding the behavior of an optimization algorithm in deep learning.
        Because the central flow renders explicit what was previously implicit in the discrete dynamics, the central flow provides a <b>strictly more informative representation</b> of the optimization algorithm than the "raw" update rule does.
        For example, any work 
    </p>
    <!-- <p class="body-text">
        A word on mathematical rigor: we agree that 
    </p>

    <p class="body-text">
        A word on mathematical rigor: all else being equal, more rigor is better.
        Indeed, we hope future work can figure out how to make our informal analysis more rigorous.
        Yet, the problem with rigor can function as a handicap. 
        Sometimes, we figure out that a thing is true long before we develop the right mathematical tooling to 
        Thus, while our work is not rigorous, it is ithe first true mechanism of convrgenmce . deep mathematical truehty. which undlir. 
    </p> -->

    <!-- stochastic setting -->
</body>
</html> 